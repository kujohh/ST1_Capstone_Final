#QUESTION 12 and QUESTION 13#


#LINEAR REGRESSION MODEL
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error, r2_score
from sklearn.metrics import mean_absolute_error
df=pd.read_csv('gold_price.csv')

# Creating feature matrix X and target vector y
X = df[['Open', 'High', 'Low']]
Y = df['Close']

# Train-test split
X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=30)

# Model initialization and training
model = LinearRegression()
model.fit(X_train, Y_train)

# Prediction
Y_pred = model.predict(X_test)
# Model evaluation
mse = mean_squared_error(Y_test, Y_pred)
print(f'Mean Squared Error: {mse}')
# Mean Absolute Error (MAE)
mae = mean_absolute_error(Y_test, Y_pred)
print(f'Mean Absolute Error: {mae}')

# R-squared
r2 = r2_score(Y_test, Y_pred)
print(f'R-squared: {r2}')

#POLYNOMIAL#
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import PolynomialFeatures
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_absolute_error
from sklearn.metrics import mean_squared_error, r2_score

df = pd.read_csv('gold_price.csv')

X = df[['Open', 'High', 'Low']]
Y = df['Close']

# Splitting the data into training and testing sets
X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=35)

# Polynomial features transformation
poly = PolynomialFeatures(degree=3)
X_train_poly = poly.fit_transform(X_train)
X_test_poly = poly.transform(X_test)

# Fitting the polynomial regression model
model = LinearRegression()
model.fit(X_train_poly, Y_train)

# Predicting on the test set
Y_pred = model.predict(X_test_poly)

mse = mean_squared_error(Y_test, Y_pred)
print(f'Mean Squared Error: {mse}')
mae = mean_absolute_error(Y_test, Y_pred)
print(f'Mean Absolute Error: {mae}')

r2 = r2_score(Y_test, Y_pred)
print(f'R-squared: {r2}')

#Polynomial Regression produces better results and will therefore be the one that is to be deployed#
